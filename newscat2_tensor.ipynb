{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ad01a1-8b5e-4bda-b929-0ccb8d7ada8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - category_accuracy: 0.2368 - category_loss: 3.0558 - loss: 3.4780 - sentiment_accuracy: 0.8873 - sentiment_loss: 0.4222 - val_category_accuracy: 0.4199 - val_category_loss: 2.2392 - val_loss: 2.6136 - val_sentiment_accuracy: 0.8942 - val_sentiment_loss: 0.3756\n",
      "Epoch 2/5\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - category_accuracy: 0.4710 - category_loss: 2.0269 - loss: 2.4001 - sentiment_accuracy: 0.8941 - sentiment_loss: 0.3732 - val_category_accuracy: 0.5083 - val_category_loss: 1.8691 - val_loss: 2.2400 - val_sentiment_accuracy: 0.8942 - val_sentiment_loss: 0.3714\n",
      "Epoch 3/5\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - category_accuracy: 0.5530 - category_loss: 1.6545 - loss: 2.0204 - sentiment_accuracy: 0.8954 - sentiment_loss: 0.3658 - val_category_accuracy: 0.5369 - val_category_loss: 1.7495 - val_loss: 2.1207 - val_sentiment_accuracy: 0.8942 - val_sentiment_loss: 0.3714\n",
      "Epoch 4/5\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - category_accuracy: 0.5914 - category_loss: 1.4868 - loss: 1.8482 - sentiment_accuracy: 0.8955 - sentiment_loss: 0.3614 - val_category_accuracy: 0.5481 - val_category_loss: 1.7018 - val_loss: 2.0723 - val_sentiment_accuracy: 0.8942 - val_sentiment_loss: 0.3711\n",
      "Epoch 5/5\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - category_accuracy: 0.6215 - category_loss: 1.3594 - loss: 1.7150 - sentiment_accuracy: 0.8967 - sentiment_loss: 0.3556 - val_category_accuracy: 0.5538 - val_category_loss: 1.6796 - val_loss: 2.0510 - val_sentiment_accuracy: 0.8946 - val_sentiment_loss: 0.3714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2854dc04050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ STEP 1: IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ✅ STEP 2: LOAD DATA\n",
    "df = pd.read_json(\"News_Category_Dataset_v3.json\", lines=True)\n",
    "df = df[[\"headline\", \"short_description\", \"category\"]].dropna().drop_duplicates()\n",
    "\n",
    "# ✅ STEP 3: Create Sentiment Labels (Rule-Based)\n",
    "def simple_sentiment(text):\n",
    "    text = text.lower()\n",
    "    if any(w in text for w in [\"win\", \"great\", \"love\", \"happy\", \"celebration\", \"joy\"]):\n",
    "        return \"positive\"\n",
    "    elif any(w in text for w in [\"bad\", \"sad\", \"angry\", \"hate\", \"tragedy\", \"alarming\"]):\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "df[\"sentiment\"] = df[\"short_description\"].apply(simple_sentiment)\n",
    "\n",
    "# ✅ STEP 4: ENCODING\n",
    "cat_encoder = LabelEncoder()\n",
    "df[\"cat_label\"] = cat_encoder.fit_transform(df[\"category\"])\n",
    "y_cat = to_categorical(df[\"cat_label\"])\n",
    "\n",
    "sent_encoder = LabelEncoder()\n",
    "df[\"sent_label\"] = sent_encoder.fit_transform(df[\"sentiment\"])\n",
    "y_sent = to_categorical(df[\"sent_label\"])\n",
    "\n",
    "# ✅ STEP 5: TEXT TOKENIZATION\n",
    "sentences = df[\"headline\"].astype(str).values\n",
    "max_words = 10000\n",
    "max_len = 25\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "X = pad_sequences(tokenizer.texts_to_sequences(sentences), maxlen=max_len)\n",
    "\n",
    "# ✅ STEP 6: SPLIT DATA\n",
    "X_train, X_test, y_cat_train, y_cat_test, y_sent_train, y_sent_test = train_test_split(\n",
    "    X, y_cat, y_sent, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ✅ STEP 7: MULTIPLE OUTPUT MODEL\n",
    "inp = Input(shape=(max_len,))\n",
    "x = Embedding(max_words, 64)(inp)\n",
    "x = LSTM(64)(x)\n",
    "\n",
    "out_category = Dense(y_cat.shape[1], activation='softmax', name='category')(x)\n",
    "out_sentiment = Dense(y_sent.shape[1], activation='softmax', name='sentiment')(x)\n",
    "\n",
    "model = Model(inputs=inp, outputs=[out_category, out_sentiment])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'category': 'categorical_crossentropy', 'sentiment': 'categorical_crossentropy'},\n",
    "    metrics={'category': 'accuracy', 'sentiment': 'accuracy'}\n",
    ")\n",
    "\n",
    "# ✅ STEP 8: TRAIN\n",
    "model.fit(\n",
    "    X_train,\n",
    "    {'category': y_cat_train, 'sentiment': y_sent_train},\n",
    "    validation_split=0.1,\n",
    "    epochs=5,\n",
    "    batch_size=256,\n",
    "    callbacks=[EarlyStopping(patience=2)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c319393-6761-4e43-a37c-7d8d2de4c78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n"
     ]
    }
   ],
   "source": [
    "headline = \"NASA Launches New Satellite\"\n",
    "\n",
    "# Convert to sequence\n",
    "seq = tokenizer.texts_to_sequences([headline])\n",
    "padded_input = pad_sequences(seq, maxlen=max_len)\n",
    "\n",
    "# Make prediction\n",
    "pred_cat, pred_sent = model.predict(padded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f2579be-61c3-4e2f-9da4-01821bb9c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.8271870e-03 4.9993733e-04 1.4080611e-03 2.7839690e-03 2.3692154e-04\n",
      "  1.0437539e-03 2.3443110e-03 8.2195096e-04 1.5411191e-04 2.6266623e-04\n",
      "  1.3880951e-03 2.6678145e-02 3.5265955e-04 3.8696909e-03 6.3549313e-03\n",
      "  2.7924595e-02 1.6146407e-02 8.0445257e-04 2.1648947e-02 4.2519314e-04\n",
      "  8.0663699e-04 1.3456309e-04 2.4478736e-03 1.0000396e-03 3.0713754e-03\n",
      "  8.6234213e-04 1.0380455e-03 6.9304156e-01 8.6326245e-04 4.6829114e-04\n",
      "  1.1436378e-03 1.7862410e-03 2.6040103e-03 6.0780975e-03 2.9947734e-02\n",
      "  9.6796907e-04 5.9763395e-05 1.5806509e-02 1.0502318e-01 7.9431041e-04\n",
      "  2.8842974e-03 1.0194301e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d0bb091-72cf-4880-b84c-ae4dc7cd1645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📰 Headline: a boy awarded with 1 million dollars\n",
      "📂 Predicted Category: QUEER VOICES\n",
      "🙂 Predicted Sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "# 👇 Required for inverse transformation (convert label index → original label)\n",
    "cat_labels = cat_encoder.inverse_transform(np.arange(y_cat.shape[1]))\n",
    "sent_labels = sent_encoder.inverse_transform(np.arange(y_sent.shape[1]))\n",
    "\n",
    "# 👇 Function to predict from user input\n",
    "def predict_headline(headline_text):\n",
    "    # Preprocess input\n",
    "    seq = tokenizer.texts_to_sequences([headline_text])\n",
    "    padded = pad_sequences(seq, maxlen=max_len)\n",
    "    \n",
    "    # Predict\n",
    "    pred_cat, pred_sent = model.predict(padded, verbose=0)\n",
    "    \n",
    "    # Decode predictions\n",
    "    pred_cat_label = cat_labels[np.argmax(pred_cat)]\n",
    "    pred_sent_label = sent_labels[np.argmax(pred_sent)]\n",
    "    \n",
    "    print(\"📰 Headline:\", headline_text)\n",
    "    print(\"📂 Predicted Category:\", pred_cat_label)\n",
    "    print(\"🙂 Predicted Sentiment:\", pred_sent_label)\n",
    "\n",
    "# ✅ Example usage:\n",
    "predict_headline(\"a boy awarded with 1 million dollars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fba6d3-ac93-49af-9c32-0098ef82ee57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
