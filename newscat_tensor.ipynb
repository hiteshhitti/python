{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37877b90-fc94-41e8-86d5-a186b0ed50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - cat1_accuracy: 0.8296 - cat1_loss: 0.3468 - cat2_accuracy: 0.8848 - cat2_loss: 0.2651 - cat3_accuracy: 0.8713 - cat3_loss: 0.3064 - loss: 0.9183 - val_cat1_accuracy: 0.9404 - val_cat1_loss: 0.1672 - val_cat2_accuracy: 0.9499 - val_cat2_loss: 0.1270 - val_cat3_accuracy: 0.9498 - val_cat3_loss: 0.1437 - val_loss: 0.4395\n",
      "Epoch 2/5\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - cat1_accuracy: 0.9661 - cat1_loss: 0.0990 - cat2_accuracy: 0.9733 - cat2_loss: 0.0725 - cat3_accuracy: 0.9727 - cat3_loss: 0.0822 - loss: 0.2537 - val_cat1_accuracy: 0.9297 - val_cat1_loss: 0.1897 - val_cat2_accuracy: 0.9448 - val_cat2_loss: 0.1515 - val_cat3_accuracy: 0.9436 - val_cat3_loss: 0.1619 - val_loss: 0.5046\n",
      "Epoch 3/5\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - cat1_accuracy: 0.9868 - cat1_loss: 0.0398 - cat2_accuracy: 0.9894 - cat2_loss: 0.0321 - cat3_accuracy: 0.9901 - cat3_loss: 0.0325 - loss: 0.1044 - val_cat1_accuracy: 0.9267 - val_cat1_loss: 0.2528 - val_cat2_accuracy: 0.9376 - val_cat2_loss: 0.2023 - val_cat3_accuracy: 0.9402 - val_cat3_loss: 0.2157 - val_loss: 0.6719\n",
      "Epoch 4/5\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - cat1_accuracy: 0.9940 - cat1_loss: 0.0193 - cat2_accuracy: 0.9943 - cat2_loss: 0.0171 - cat3_accuracy: 0.9947 - cat3_loss: 0.0167 - loss: 0.0531 - val_cat1_accuracy: 0.9268 - val_cat1_loss: 0.3258 - val_cat2_accuracy: 0.9358 - val_cat2_loss: 0.2481 - val_cat3_accuracy: 0.9388 - val_cat3_loss: 0.2684 - val_loss: 0.8447\n",
      "Epoch 5/5\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - cat1_accuracy: 0.9959 - cat1_loss: 0.0120 - cat2_accuracy: 0.9963 - cat2_loss: 0.0103 - cat3_accuracy: 0.9970 - cat3_loss: 0.0089 - loss: 0.0312 - val_cat1_accuracy: 0.9249 - val_cat1_loss: 0.3600 - val_cat2_accuracy: 0.9344 - val_cat2_loss: 0.2848 - val_cat3_accuracy: 0.9385 - val_cat3_loss: 0.3000 - val_loss: 0.9462\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - cat1_accuracy: 0.9229 - cat1_loss: 0.3488 - cat2_accuracy: 0.9419 - cat2_loss: 0.2301 - cat3_accuracy: 0.9397 - cat3_loss: 0.2866 - loss: 0.8655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8590531349182129,\n",
       " 0.3407551646232605,\n",
       " 0.2317945659160614,\n",
       " 0.287570595741272,\n",
       " 0.9241997003555298,\n",
       " 0.9414750933647156,\n",
       " 0.938443124294281]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load and prepare data\n",
    "df = pd.read_json(\"News_Category_Dataset_v3.json\", lines=True)\n",
    "df = df[['headline', 'category']]\n",
    "df = df.dropna()\n",
    "\n",
    "# Keep top 3 categories for multi-output demo\n",
    "top3 = df['category'].value_counts().nlargest(3).index.tolist()\n",
    "df = df[df['category'].isin(top3)]\n",
    "\n",
    "# Simulate multiple outputs (just for demo)\n",
    "# Let's say we split category into 3 parallel outputs\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df['cat1'] = df['category'].apply(lambda x: 1 if x == top3[0] else 0)\n",
    "df['cat2'] = df['category'].apply(lambda x: 1 if x == top3[1] else 0)\n",
    "df['cat3'] = df['category'].apply(lambda x: 1 if x == top3[2] else 0)\n",
    "\n",
    "# 2. Tokenize text\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['headline'])\n",
    "sequences = tokenizer.texts_to_sequences(df['headline'])\n",
    "X = pad_sequences(sequences, maxlen=20)\n",
    "\n",
    "# 3. Prepare outputs\n",
    "y1 = df['cat1'].values\n",
    "y2 = df['cat2'].values\n",
    "y3 = df['cat3'].values\n",
    "\n",
    "X_train, X_test, y1_train, y1_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "_, _, y2_train, y2_test = train_test_split(X, y2, test_size=0.2, random_state=42)\n",
    "_, _, y3_train, y3_test = train_test_split(X, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Build multi-output model\n",
    "input_layer = tf.keras.Input(shape=(20,))\n",
    "embed = tf.keras.layers.Embedding(10000, 64)(input_layer)\n",
    "flat = tf.keras.layers.Flatten()(embed)\n",
    "dense1 = tf.keras.layers.Dense(128, activation='relu')(flat)\n",
    "dense2 = tf.keras.layers.Dense(64, activation='relu')(dense1)\n",
    "\n",
    "# Each output layer uses sigmoid\n",
    "out1 = tf.keras.layers.Dense(1, activation='sigmoid', name='cat1')(dense2)\n",
    "out2 = tf.keras.layers.Dense(1, activation='sigmoid', name='cat2')(dense2)\n",
    "out3 = tf.keras.layers.Dense(1, activation='sigmoid', name='cat3')(dense2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=[out1, out2, out3])\n",
    "\n",
    "# 5. Compile model with multiple losses\n",
    "model.compile(\n",
    "    loss={\n",
    "        'cat1': 'binary_crossentropy',\n",
    "        'cat2': 'binary_crossentropy',\n",
    "        'cat3': 'binary_crossentropy'\n",
    "    },\n",
    "    optimizer='adam',\n",
    "    metrics={\n",
    "        'cat1': 'accuracy',\n",
    "        'cat2': 'accuracy',\n",
    "        'cat3': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 6. Train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    {'cat1': y1_train, 'cat2': y2_train, 'cat3': y3_train},\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# 7. Evaluate\n",
    "model.evaluate(X_test, {'cat1': y1_test, 'cat2': y2_test, 'cat3': y3_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b318b8e-6dcb-4b95-90e3-8cccf163958e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "POLITICS: Yes (1.00)\n",
      "WELLNESS: No (0.00)\n",
      "ENTERTAINMENT: No (0.00)\n"
     ]
    }
   ],
   "source": [
    "sample_text = [\"Facebook faces government inquiry over data privacy issues\"]\n",
    "seq = tokenizer.texts_to_sequences(sample_text)\n",
    "pad = pad_sequences(seq, maxlen=20)\n",
    "p1, p2, p3 = model.predict(pad)\n",
    "\n",
    "for i, prob in enumerate([p1, p2, p3]):\n",
    "    print(f\"{top3[i]}: {'Yes' if prob[0][0]>0.5 else 'No'} ({prob[0][0]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb0700f2-5cf4-4787-964a-3b90c413552b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Predicted categories:\n",
      "✔️ POLITICS\n"
     ]
    }
   ],
   "source": [
    "# Sample test headline\n",
    "sample_text = [\"Facebook faces government inquiry over data privacy issues\"]\n",
    "\n",
    "# Step 1: Tokenize and pad\n",
    "sample_seq = tokenizer.texts_to_sequences(sample_text)\n",
    "sample_pad = pad_sequences(sample_seq, maxlen=20)\n",
    "\n",
    "# Step 2: Predict using model\n",
    "pred1, pred2, pred3 = model.predict(sample_pad)\n",
    "\n",
    "# Step 3: Threshold each output\n",
    "threshold = 0.5\n",
    "predicted = {\n",
    "    top3[0]: int(pred1[0][0] > threshold),\n",
    "    top3[1]: int(pred2[0][0] > threshold),\n",
    "    top3[2]: int(pred3[0][0] > threshold),\n",
    "}\n",
    "\n",
    "# Step 4: Show predicted labels\n",
    "print(\"Predicted categories:\")\n",
    "for label, val in predicted.items():\n",
    "    if val == 1:\n",
    "        print(\"✔️\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d38f19-86bf-4cf9-9ea6-21f1aff6cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: bleach in d:\\python\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in d:\\python\\lib\\site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer in d:\\python\\lib\\site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in d:\\python\\lib\\site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in d:\\python\\lib\\site-packages (from kaggle) (4.25.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\python\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in d:\\python\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: requests in d:\\python\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in d:\\python\\lib\\site-packages (from kaggle) (75.1.0)\n",
      "Requirement already satisfied: six>=1.10 in d:\\python\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode in d:\\python\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in d:\\python\\lib\\site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in d:\\python\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: webencodings in d:\\python\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in d:\\python\\lib\\site-packages (from bleach->kaggle) (24.1)\n",
      "Requirement already satisfied: colorama in d:\\python\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.7.4.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68d9b4-79fe-4a9d-9e2d-fb4f7da20a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
